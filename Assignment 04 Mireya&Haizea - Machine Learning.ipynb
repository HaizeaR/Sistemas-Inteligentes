{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"2021 Assignment 04 Mireya&Haizea - Machine Learning.ipynb","private_outputs":true,"provenance":[{"file_id":"14q9dww1DAE3F6LRowuqpHTE1mbOyMSDU","timestamp":1616059203063},{"file_id":"1U7NEdBZTlqeakQNLdcEme5aBvFLt6OLz","timestamp":1614956019899},{"file_id":"1mRnSstYt9zqDbaNknFdgUO4_tcEPEByT","timestamp":1613642132869},{"file_id":"1qqG2SK1xU1cr9MKJ1GLm9sQ2hCWyioeP","timestamp":1612274009316},{"file_id":"1jxM7KY2LbuaMwGM3xYUZcNMd24l1cW5z","timestamp":1612272792122},{"file_id":"1ztT-p4zzi9SmESBu3idnMctacEYLXBeS","timestamp":1612271764394},{"file_id":"1SpUyfEvtgSfNvCw6pbuyJlBzAIXcdeON","timestamp":1612270801578},{"file_id":"1s4EKBV-TNWM1OVrtj1iffkof10nGTM4N","timestamp":1612269929665},{"file_id":"1CdrY4WruzeUrYwKk8XO4FdTwvfFX2b8D","timestamp":1612269493316}],"collapsed_sections":["JA1cLDWwZgcu","pyazpT0ll7m3","CjMyj_JE4xen","mJXEyxyX5IZS","NUPU8YstCv9b"],"toc_visible":true},"kernelspec":{"name":"ir","display_name":"R"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"JA1cLDWwZgcu"},"source":["#Intelligent Systems - Assignment 4 - Machine Learning\n","\n","- Member Names: **Mireya Quintana and Haizea Rodriguez**\n","- Group ID: **C**\n","- Assignment: **04**\n","- Date: **20/05/2021**\n","- Time spent in the assignment: **7h**\n","- Proportion of effort done by members of the group: **50/50**\n","- Doubts and difficulties that arose during the realization:\n","\n","\n","---\n","\n","**General instructions**\n"," 1. If you use a function of a certain library, do not forget to include in the packages vector\n"," 2. Do not forget to comment on the code, especially those non-trivial commands (part of the rating depends on the cleaning of the code)\n"," 3. It is strongly recommended to test any implemented function in order to    check for its proper operation\n","\n","---\n","\n"," **Submission**\n","- Print the notebook in a PDF file with all the sections expanded and all the cells executed, in a way all the code can be seen, and all the results are shown.\n","- Save the notebook as ipynb file.\n","- Submit both files, in addition to any input file needed for its execution in a zip folder into ALUD\n","\n","---\n","\n","**Evaluation**\n","- Total Evaluation - 25%\n","  - Correct and error-free execution - 15%\n","  - Documentation of analysis of results - 10%\n","\n","---\n","**Deadline**\n","May 20th"]},{"cell_type":"markdown","metadata":{"id":"xKVvuewiTIsO"},"source":["We have included some libraries in order to show the correlaion matrix. The loading of them it is quite slow. "]},{"cell_type":"code","metadata":{"id":"ozwk8xmIyg3d"},"source":["# PLEASE, INCLUDE HERE IF YOU USE ANY ADDITIONAL LIBRARY\n","packages = c(\"glue\",\"ggplot2\",\"gridExtra\",\"tidyverse\",\"caret\",\"rpart\",\"e1071\",\"readr\", \"Matrix\", \"reshape2\", \"dplyr\", \"tidyr\", \"ggvis\", \"corrplot\")\n","newpack  = packages[!(packages %in% installed.packages()[,\"Package\"])]\n","if(length(newpack)) install.packages(newpack)\n","a=lapply(packages, library, character.only=TRUE)\n","rm(list = ls())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-mjP77s0mjvA"},"source":["## Linear Regression\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"rn8q56bvpjFn"},"source":["### Data Description 📚\n","In this part of the assignment you are going to answer the question **How accurately can average, minimum and maximum temperature be predicted from historical data?**\n","\n","We will analyse the margin of error when predicting the minimum, average and maximum temperature based on historical data.\n","\n","We will use a [CSV](https://drive.google.com/open?id=1A6Z0Azqu-c-mFDoFcmbCvnGeylHeby1N&authuser=enrique.onieva%40deusto.es&usp=drive_fs) available in the Drive folder with data from the [AEMET OpenData service](http://www.aemet.es/es/datos_abiertos/AEMET_OpenData) (*loiu_2000-01_2021-03.csv*).\n","\n","Loiu Airport weather station between 1 January 2010 and 31 March 2021.\n","The dataset has 4018 records of 20 attributes ([see description here](https://docs.google.com/spreadsheets/d/1pVy1eDi2YEUzetP0cEbxDz09uuDkQ7kUIgremgyNdnM/edit#gid=1743573338)). \n"]},{"cell_type":"markdown","metadata":{"id":"7vckdPDOqqh8"},"source":["###  You are asked to: 🚨\n","1. Read the provided file and store in a data.frame\n","2. Select up to 5 columns (without the target) to make predictions.\n","3. Repeat 10 times:\n","  - Randomly divide data in train (80%) and test (20%)\n","    - 🔎 For this, you can use the [createDataPartition](https://www.rdocumentation.org/packages/caret/versions/6.0-86/topics/createDataPartition) function of the *caret* package as:\n","    - createDataPartition(y = **data$Target**, p = **percentage**, list = FALSE)\n","  - Train a linear regression model\n","    - 🔎 For this, you have to use the [lm](https://www.rdocumentation.org/packages/stats/versions/3.6.2/topics/lm) function as:\n","    - model = lm(**Target~xxxxxxx**, **training.data**)\n","  - Make predictions over the test data\n","    - 🔎 You will have to use the predict function as:\n","    - predictions = predict(**model**,**test.data**)\n","  - Calculate and print Mean Absolute Error (MAE)\n","    - 🔎 You can calculate MAE as:\n","    - mean(abs(prediction - test_data$Target))\n","\n","**(You will have to do this procedure three times: one for prediction of average, other minimum and the third one for maximum temperature)**\n","\n","**You have to present:**\n","- Justification  used to select the attributes for each one of the predictions.\n","- Table with MAE results of the 10 iterations\n","- Average MAE and Standar Deviation get from the 10 iterations "]},{"cell_type":"markdown","metadata":{"id":"Ff7oQLDeVTtH"},"source":["### Your solution here 💻"]},{"cell_type":"markdown","metadata":{"id":"wZ16OLD6ABRY"},"source":["####Reading and cleaning data"]},{"cell_type":"markdown","metadata":{"id":"bTVpzzxo2oY5"},"source":["The CSV uploaded to our gitHub repository.\n","The data contains information about the weather in Loiu from 2010 to 2021\n"]},{"cell_type":"code","metadata":{"id":"MRdMXBBleUqX"},"source":["# Read the csv file and store it into a data.frame\n","fileLoiu = \"https://raw.githubusercontent.com/HaizeaR/Sistemas-Inteligentes-Files/main/loiu_2000-01_2021-03.csv\"\n","LoiuData = read.csv(fileLoiu)\n","knitr::kable(head(LoiuData), caption = \"A glipmse of the data\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rs7zvkK4kuk6"},"source":["One of the most important parts of working with sets  of data is preparing it for the exploration. The first step traken after reading the file is visualizing a summary of all the variables indicating the type as well. "]},{"cell_type":"code","metadata":{"id":"r3adj0Z7lEov"},"source":["#This will show a glipse of the values we have\n","summary(LoiuData)\n","#This will indicate the type of each variable\n","str(LoiuData)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jSOw0ZOylXTl"},"source":["Once we have understood what we are working with the 1st task will be changing the type of some variables.\n","\n","\n",">In the case of **hours** we have \"strange\" values. The word \"Varias\" appears several times. Our approach has been changin it to 0 with the following code: \n","\n","\n","\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"JD9caoBXnVbd"},"source":["#Remove all the values that may give us problems \n","#Varias could generate Nan's so we will change it to 0 \n","\n","LoiuData$horatmin=ifelse(LoiuData$horatmin==\"Varias\",0, as.character(LoiuData$horatmin))\n","LoiuData$horatmax=ifelse(LoiuData$horatmax==\"Varias\",0, as.character(LoiuData$horatmax))\n","LoiuData$horaPresMin=ifelse(LoiuData$horaPresMin==\"Varias\",0, as.character(LoiuData$horaPresMin))\n","LoiuData$horaracha=ifelse(LoiuData$horaracha==\"Varias\",0, as.character(LoiuData$horaracha))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qnkwoe8Zntj3"},"source":[">Then we have decided to stay with just the hour part. If the store value is 21:36 we will keep 21. \n","\n",">After doing all the procedure we will change the Hours to integer, so we can evaluate them as numbers. "]},{"cell_type":"code","metadata":{"id":"wqgGowJSnYIb"},"source":["# The SUB will remove all the not needed parts giving us the option of keeping just the H part\n","# If data is H:M we will just work with H which refers to Hours\n","\n","LoiuData$horaPresMin = as.factor(LoiuData$horaPresMin)\n","LoiuData$horaPresMin = sub(\"\\\\:.*\", \"\",LoiuData$horaPresMin)\n","LoiuData$horaPresMin = as.integer(LoiuData$horaPresMin)\n","#LoiuData$horaPresMin = na.omit(LoiuData$horaPresMin)\n","\n","LoiuData$horaracha = as.factor(LoiuData$horaracha)\n","LoiuData$horaracha = sub(\"\\\\:.*\", \"\",LoiuData$horaracha)\n","LoiuData$horaracha = as.integer(LoiuData$horaracha)\n","#LoiuData$horaracha = na.omit(LoiuData$horaracha)\n","\n","LoiuData$horatmax = as.factor(LoiuData$horatmax)\n","LoiuData$horatmax = sub(\"\\\\:.*\", \"\", LoiuData$horatmax)\n","LoiuData$horatmax = as.integer(LoiuData$horatmax)\n","#LoiuData$horatmax = na.omit(LoiuData$horatmax)\n","\n","LoiuData$horatmin = as.character(LoiuData$horatmin)\n","LoiuData$horatmin = sub(\"\\\\:.*\", \"\", LoiuData$horatmin)\n","LoiuData$horatmin = as.integer(LoiuData$horatmin)\n","#LoiuData$horatmin = na.omit(LoiuData$horatmin)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CrYgbb7Rnm7S"},"source":["\n","> We will **create a new variable** \"mes\". We believe that it could be interesting to know the month to calculate the temperature and we will test if our prediction is correct later on. \n"]},{"cell_type":"code","metadata":{"id":"7YAPt-8lnamf"},"source":["# CREATE A NEW VARIABLE \n","LoiuData$mes <- substr(LoiuData$fecha,6,7)\n","LoiuData$mes = as.integer(LoiuData$mes)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_Ya6yWMpkLov"},"source":["We change the type os some variables to factor in order to know if they are a collection of values or it is always the same one. "]},{"cell_type":"code","metadata":{"id":"Izq8XfDhneLZ"},"source":["LoiuData$fecha = as.factor(LoiuData$fecha) \n","LoiuData$nombre = as.factor(LoiuData$nombre) \n","LoiuData$provincia = as.factor(LoiuData$provincia)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"O2oN-TORnxGL"},"source":["> We are going to erase all the NaN's because keeping them may create problems"]},{"cell_type":"code","metadata":{"id":"sJKgDgIXndNr"},"source":["LoiuData = LoiuData %>% drop_na()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HgCpoJygfYGe"},"source":["# Verify that all the cahnges are done correctly\n","summary(LoiuData)\n","str(LoiuData)\n","knitr::kable(head(LoiuData), caption = \"A glipmse of the data\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"due39X7Kn7CM"},"source":["> **Erase** all the columns that we considerer that are not relevant for the evaluation\n","\n","> **Nombre, Provincia, Indicativo and Altitud** have always the same value.\n","> **Hora Pres Max** has a lot of \"Varias\" values and all the rest are either 24 or 0 so we are going to remove it because we believe it does not provide a great deal of useful information."]},{"cell_type":"code","metadata":{"id":"fn2EEU2dvJOR"},"source":["LoiuData = LoiuData %>% select(-nombre,-provincia, -indicativo, -altitud, -horaPresMax)\n","#we have decided to get rid off horapremax because most values were \"Varias\" which do not give us a lot of infomation"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iD40QzWlvOH5"},"source":["knitr::kable(head(LoiuData), caption = \"A glipmse of the data\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eJw-ta1P4hLp"},"source":["str(LoiuData)\n","summary(LoiuData)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5--PHEbz_8qp"},"source":["####Correlation matrix"]},{"cell_type":"markdown","metadata":{"id":"lkN48lCBohiH"},"source":["DEFINITION: \n","\n","A correlation matrix is a table which displays the correlation coefficients for different variables. The matrix depicts the correlation between all the possible pairs of values in a table.\n","\n","A correlation matrix consists of rows and columns that show the variables. Each cell in a table contains the correlation coefficient.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"V7HoBmJAo73b"},"source":["We are going to use the correlation matrix to obtain the 5 best variables for each case, tmax, tmin ant tavg.\n","\n","Variables can be directly (blue) or indirectly (red) correlated and those ones closer to 1 or -1 will be the most interesting ones. \n","\n"]},{"cell_type":"markdown","metadata":{"id":"14CJsrrN3SKo"},"source":["To calculate the correlation matrix only numerical values can be used this is the reason why we only calculate for the columns that go from tmed to mes "]},{"cell_type":"code","metadata":{"id":"dUGgWp2zrQEn"},"source":["# Only numerical values can be correlated\n","correlation<- LoiuData %>% select(tmed:mes)\n","\n","M <- cor(correlation) # correlation matrix\n","\n","# By changing the method parameter the type of visualization changes \n","# “circle”, “square”, “ellipse”, “number”, “shade”, “color”, “pie”\n","corrplot(M, method = \"number\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DRlt299i5QtD"},"source":["RESULTS of correlation matrix \n","\n",">TMAX \n","\n","> - tmed(0.95)\n","> - tmin(0.77)\n","> - sol(0.56)\n","> - prec(-0.33)\n","> - mes(0.27)\n","\n","> TMIN\n","> - tmed(0.93)\n","> - tmax(0.77)\n","> - mes(0.3)\n","> - presMax(-0.25)\n","> - prec (-0.14)\n","\n",">TAVG\n","> - tmax(0.95)\n","> - tmin(0.93)\n","> - sol(0.35)\n","> - mes(0.30)\n","> - prec(-0.25)\n","\n","\n","\n","*(values obtain looking at the row of the Target variable)*\n"]},{"cell_type":"markdown","metadata":{"id":"d5Jkq6_JkqVy"},"source":["We believe that the obtained variables are the ones that are truthly related, it makes total sense that the sun will be an important variable when trying to predict the temperature, as well as the others."]},{"cell_type":"markdown","metadata":{"id":"Bt52gGdwqyyx"},"source":["####MAX"]},{"cell_type":"code","metadata":{"id":"v9q-lp1zhw4S"},"source":["LoiuDataMAX = data.frame(LoiuData$tmax, LoiuData$tmed, LoiuData$tmin, LoiuData$sol, LoiuData$prec, LoiuData$mes)\n","knitr::kable(head(LoiuDataMAX))\n","\n","valuesMAEmax =c()\n","\n","#Repeat the procces 10 times\n","for(i in 1:10){\n","  print(glue(\"--------------------------------------------------\"))\n","  print(glue(\"Number of iteration: {i}\"))\n","\n","  knitr::kable(head(LoiuDataMAX), caption = \"A glipmse of the data\")\n","\n","  # Get indexes to do partitions\n","  perc = 0.80\n","  index.train = caret::createDataPartition(y = LoiuDataMAX$LoiuData.tmax, p = perc, list = FALSE)\n","\n","  # Getting partitions\n","  data.train = LoiuDataMAX[ index.train, ]\n","  data.test  = LoiuDataMAX[-index.train, ]\n","  print(glue(\"\"))\n","  print(glue(\"Size of the training set: {nrow(data.train)}\"))\n","  print(glue(\"Size of the test set: {nrow(data.test)}\"))\n","\n","  # Create Linear Model using training data. Formula = all the columns except Score\n","  model = lm(formula = LoiuData.tmax ~., data = data.train)\n","  print(model)\n","\n","  # Make the prediction using the model and test data\n","  prediction = predict(model, data.test)\n"," \n","  #print(summary(prediction)) # we have found that the prediction contained some NAs we are going to erase them so we obtain a mean value\n","  prediction = na.omit(prediction)\n","  # Calculate Mean Average Error\n","  mean_abs_error = mean(abs(prediction - data.test$LoiuData.tmax))\n"," \n","  print(glue(\"Mean Absolute Error: {mean_abs_error}\"))\n","\n","  valuesMAEmax[i] = mean_abs_error\n","\n","}\n","print(glue(\"\"))\n","print(glue(\".......................\"))\n","print(glue(\"RESULTS\"))\n","knitr::kable(valuesMAEmax)\n","print(glue(\"Mean MAE: {mean(valuesMAEmax)}\"))\n","print(glue(\"Standard Deviation of MAE: {sd(valuesMAEmax)}\"))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JnPHvZPUq4oG"},"source":["####MIN"]},{"cell_type":"code","metadata":{"id":"DrsykmiijTzH"},"source":["LoiuDataMIN = data.frame(LoiuData$tmin, LoiuData$tmed, LoiuData$tmax, LoiuData$mes, LoiuData$presMax, LoiuData$prec)\n","knitr::kable(head(LoiuDataMIN))\n","\n","valuesMAEmin =c()\n","\n","#Repeat the procces 10 times\n","for(i in 1:10){\n","  print(glue(\"--------------------------------------------------\"))\n","  print(glue(\"Number of iteration: {i}\"))\n","\n","  knitr::kable(head(LoiuDataMIN), caption = \"A glipmse of the data\")\n","\n","  # Get indexes to do partitions\n","  perc = 0.80\n","  index.train = caret::createDataPartition(y = LoiuDataMIN$LoiuData.tmin, p = perc, list = FALSE)\n","\n","  # Getting partitions\n","  data.train = LoiuDataMIN[ index.train, ]\n","  data.test  = LoiuDataMIN[-index.train, ]\n","  print(glue(\"\"))\n","  print(glue(\"Size of the training set: {nrow(data.train)}\"))\n","  print(glue(\"Size of the test set: {nrow(data.test)}\"))\n","\n","  # Create Linear Model using training data. Formula = all the columns except Score\n","  model = lm(formula = LoiuData.tmin ~., data = data.train)\n","  print(model)\n","\n","  # Make the prediction using the model and test data\n","  prediction = predict(model, data.test)\n"," \n","  #print(summary(prediction)) # we have found that the prediction contained some NAs we are going to erase them so we obtain a mean value\n","  prediction = na.omit(prediction)\n","  # Calculate Mean Average Error\n","  mean_abs_error = mean(abs(prediction - data.test$LoiuData.tmin))\n"," \n","  print(glue(\"Mean Absolute Error: {mean_abs_error}\"))\n","\n","  valuesMAEmin[i] = mean_abs_error\n","\n","}\n","knitr::kable(valuesMAEmin)\n","\n","print(glue(\".......................\"))\n","print(glue(\"Mean MAE: {mean(valuesMAEmin)}\"))\n","print(glue(\"Standard Deviation of MAE: {sd(valuesMAEmin)}\"))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tOESn2wLq-Jb"},"source":["####AVERAGE"]},{"cell_type":"code","metadata":{"id":"Gd7zUIIpe47y"},"source":["LoiuDataAVG = data.frame(LoiuData$tmed, LoiuData$tmax, LoiuData$tmin, LoiuData$sol, LoiuData$mes, LoiuData$prec)\n","knitr::kable(head(LoiuDataAVG))\n","\n","valuesMAEavg =c()\n","\n","#Repeat the procces 10 times\n","for(i in 1:10){\n","  print(glue(\"--------------------------------------------------\"))\n","  print(glue(\"Number of iteration: {i}\"))\n","\n","  knitr::kable(head(LoiuDataAVG), caption = \"A glipmse of the data\")\n","\n","  # Get indexes to do partitions\n","  perc = 0.80\n","  index.train = caret::createDataPartition(y = LoiuDataAVG$LoiuData.tmed, p = perc, list = FALSE)\n","\n","  # Getting partitions\n","  data.train = LoiuDataAVG[ index.train, ]\n","  data.test  = LoiuDataAVG[-index.train, ]\n","  print(glue(\"\"))\n","  print(glue(\"Size of the training set: {nrow(data.train)}\"))\n","  print(glue(\"Size of the test set: {nrow(data.test)}\"))\n","\n","  # Create Linear Model using training data. Formula = all the columns except Score\n","  model = lm(formula = LoiuData.tmed ~., data = data.train)\n","  print(model)\n","\n","  # Make the prediction using the model and test data\n","  prediction = predict(model, data.test)\n"," \n","  #print(summary(prediction)) # we have found that the prediction contained some NAs we are going to erase them so we obtain a mean value\n","  prediction = na.omit(prediction)\n","  # Calculate Mean Average Error\n","  mean_abs_error = mean(abs(prediction - data.test$LoiuData.tmed))\n"," \n","  print(glue(\"Mean Absolute Error: {mean_abs_error}\"))\n","\n","  valuesMAEavg[i] = mean_abs_error\n","\n","}\n","knitr::kable(valuesMAEavg)\n","\n","print(glue(\".......................\"))\n","print(glue(\"Mean MAE: {mean(valuesMAEavg)}\"))\n","print(glue(\"Standard Deviation of MAE: {sd(valuesMAEavg)}\"))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pwgCe0gPqtJZ"},"source":["Write your analysis or answers to questions here (use as many cells  as needed)"]},{"cell_type":"markdown","metadata":{"id":"1oGGwZVH7Bmg"},"source":["#### RESULTS"]},{"cell_type":"markdown","metadata":{"id":"GZRxYx5I8U4I"},"source":["This is done just with the purpose of visualizing everything together "]},{"cell_type":"code","metadata":{"id":"YVdVRH5l69d2"},"source":["print(glue(\"The results of the 3 cases \"))\n","print(glue(\"...........................\"))\n","\n","results = data.frame(valuesMAEmax,valuesMAEmin,valuesMAEavg)\n","knitr::kable(results)\n","print(glue(\"\"))\n","print(glue(\"MAX\"))\n","print(glue(\"................\"))\n","print(glue(\"Mean MAE: {mean(valuesMAEmax)}\"))\n","print(glue(\"Standard Deviation of MAE: {sd(valuesMAEmax)}\"))\n","print(glue(\"\"))\n","print(glue(\"MIN\"))\n","print(glue(\"................\"))\n","print(glue(\"Mean MAE: {mean(valuesMAEmin)}\"))\n","print(glue(\"Standard Deviation of MAE: {sd(valuesMAEmin)}\"))\n","print(glue(\"\"))\n","print(glue(\"AVG\"))\n","print(glue(\"................\"))\n","print(glue(\"Mean MAE: {mean(valuesMAEavg)}\"))\n","print(glue(\"Standard Deviation of MAE: {sd(valuesMAEavg)}\"))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YrMQGOdu55vj"},"source":["### An End-to-End example 👀\n","(but please, in your solution do not do like me and use more than one cell to organize the code, when possible 🙂)"]},{"cell_type":"code","metadata":{"id":"Uds46vMS6OZp"},"source":["data = read.csv(file=\"https://raw.githubusercontent.com/HaizeaR/Sistemas-Inteligentes-Files/main/2020%20-%202019%20world%20happiness.csv\", sep=\",\", header = TRUE)\n","# Remove unuseful columns\n","data = data %>% select(-Country.or.region,-Overall.rank)\n","\n","knitr::kable(head(data), caption = \"A glipmse of the data\")\n","\n","# Get indexes to do partitions\n","perc = 0.80\n","index.train = createDataPartition(y = data$Score, p = perc, list = FALSE)\n","\n","# Getting partitions\n","data.train = data[ index.train, ]\n","data.test  = data[-index.train, ]\n","print(glue(\"\"))\n","print(glue(\"Size of the training set: {nrow(data.train)}\"))\n","print(glue(\"Size of the test set: {nrow(data.test)}\"))\n","\n","# Create Linear Model using training data. Formula = all the columns except Score\n","model = lm(formula = Score ~., data = data.train)\n","print(model)\n","\n","# Make the prediction using the model and test data\n","prediction = predict(model, data.test)\n","\n","# Calculate Mean Average Error\n","mean_abs_error = mean(abs(prediction - data.test$Score))\n","print(glue(\"Mean Absolute Error: {mean_abs_error}\"))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Yef4UqDppaYP"},"source":["## Decision Trees"]},{"cell_type":"markdown","metadata":{"id":"IGs8wZHZpmEl"},"source":["### Data Description 📚\n","[Divorce prediction](https://archive.ics.uci.edu/ml/datasets/Divorce+Predictors+data+set). Within this assignment, you will **create a decision tree able to predict if a couple will divorce or not** depending of answer given to a standard psicological form.\n","\n","Data from 190 participants (49% divorced and 51% married) is available in the [Drive folder](https://drive.google.com/drive/folders/1A6Z0Azqu-c-mFDoFcmbCvnGeylHeby1N). In the folder, you also have an excel file with questions in the form. \n"]},{"cell_type":"markdown","metadata":{"id":"RVV4dr8yq32F"},"source":["### You are asked to: 🚨\n","\n","1. Read the provided file and store in a data.frame\n","2. Repeat 10 times\n","  - Randomly divide data in train (80%) and test (20%)\n","    - 🔎 For this, you can use the [createDataPartition](https://www.rdocumentation.org/packages/caret/versions/6.0-86/topics/createDataPartition) function of the *caret* package as:\n","    - createDataPartition(y = **data$Target**, p = **percentage**, list = FALSE)\n","  - Train a decision tree to predict the divorce given the responses\n","    - 🔎 For this, you have to use the [rpart](https://www.rdocumentation.org/packages/rpart/versions/4.1-15/topics/rpart) function within the *caret* package as:\n","    - model = model(**Target~xxxxxxx**, **training.data**)\n","  - Make predictions over the test data\n","    - 🔎 You will have to use the predict function as:\n","    - predictions = predict(**model**,**test.data**)\n","  - Calculate and print the accuracy of the model over the test data.\n","    - The accuracy is calculated as the percertage of hit over the giving data, or the percentage of data in which the real class is equal to the predicted one.\n","3. After the loop, build a decision tree with all the data and print it.\n","4. Explore the *tree* object in order to print the top-5 most relevant questions to predict if a couple will end in divorce or not. \n","\n","**You have to present**\n","- Top-5 most relevant questions.\n","- A printed version of the obtained tree.\n","- A table with the accuracy results for the 10 runs.\n","- Average and standard deviation of the accuracies obtained.\n"]},{"cell_type":"markdown","metadata":{"id":"pxuf2WQfVfeF"},"source":["###Your solution here 💻"]},{"cell_type":"code","metadata":{"id":"iYXkQXC6AK8M"},"source":["DivorceFile = \"https://raw.githubusercontent.com/HaizeaR/Sistemas-Inteligentes-Files/main/divorce.csv\"\n","DivorceData = read.csv(DivorceFile, header = TRUE, fill = TRUE, sep = ';')\n","knitr::kable(head(DivorceData), caption = \"A glipmse of the data\")\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9J_EqS-olkBl"},"source":["With the aim of knowing how many times a value appears we think that it is interseting to change the type from numeric to FACTOR."]},{"cell_type":"code","metadata":{"id":"Viglg-pOgLbN"},"source":["cols <- c(\"Atr1\",\"Atr2\",\"Atr3\",\"Atr4\",\"Atr5\",\"Atr6\",\"Atr7\",\"Atr8\",\"Atr9\",\"Atr10\",\"Atr11\",\"Atr12\",\"Atr13\",\"Atr14\",\"Atr15\",\"Atr16\",\"Atr17\",\"Atr18\",\"Atr19\",\"Atr20\",\"Atr21\",\"Atr22\",\"Atr23\",\"Atr24\",\"Atr25\",\"Atr26\",\"Atr27\",\"Atr28\",\"Atr29\",\"Atr30\",\"Atr31\",\"Atr32\",\"Atr33\",\"Atr34\",\"Atr35\",\"Atr36\",\"Atr37\",\"Atr38\",\"Atr39\",\"Atr40\",\"Atr41\",\"Atr42\",\"Atr43\",\"Atr44\",\"Atr45\",\"Atr46\",\"Atr47\",\"Atr48\",\"Atr49\",\"Atr50\",\"Atr51\",\"Atr52\",\"Atr53\",\"Atr54\",\"Class\")\n","# LAPPLY - apply the operation to all \n","#In this case change to factor all the columns of DivorceData\n"," \n","DivorceData$Class=ifelse(DivorceData$Class==0,\"D\", \"ND\")\n","DivorceData[cols] <- lapply(DivorceData[cols], factor)\n","summary(DivorceData)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dMtdIV0tq4bp"},"source":["overall = c()\n","questions = list()\n","\n","for(i in 1:10){\n","  print(glue(\"Iteration: {i}\"))\n","  print(glue(\"--------------------------\"))\n","  # Get indexes to do partitions\n","  perc = 0.80\n","  index.train = createDataPartition(y = DivorceData$Class, p = perc, list = FALSE)\n","\n","  # Getting partitions\n","  data.train = DivorceData[ index.train, ]\n","  data.test  = DivorceData[-index.train, ]\n","  print(glue(\"\"))\n","  print(glue(\"Size of the training set: {nrow(data.train)}\"))\n","  print(glue(\"Size of the test set: {nrow(data.test)}\"))\n","\n","  # Create Linear Model using training data. Formula = all the columns except Score\n","  model = rpart(formula = Class ~., data = data.train)\n","  \n","\n","  questions$names[i] = names(model$variable.importance[1])\n","  questions$value[i] = model$variable.importance[1]\n","\n","  print(model)\n","  #plot(model)\n","  #text(model, digits = 3)\n","  \n","  # Make the prediction using the model and test data\n","  prediction = predict(model, data.test, type= \"class\")\n","  \n","  # Display Confusion Matrix\n","  print(glue(\"\"))\n","  mat = caret::confusionMatrix(data.test$Class, prediction)\n","  print(mat$table)\n","\n","  # Print the accuracy \n","  print(glue(\"\"))\n","  print(glue(\"The model hits in {round(100*mat$overall[[1]],2)} % of the couples\"))\n"," # DivorceData =   DivorceData %>% select(-)\n","\n","  overall[i] = round(100*mat$overall[[1]],2)\n","\n","}\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MWYxQcqD8nMg"},"source":["print(glue(\"The results after the 10 iterations are the following:\"))\n","print(glue(\"- - - - - - - - - - - - - - - - - - - - - - - - - - - - -\"))\n","print(glue(\"\"))\n","print(glue(\"For each iteration the model hits the following %:\"))\n","knitr::kable(overall)\n","print(glue(\"\"))\n","print(glue(\"Average: {mean(overall)}\"))\n","print(glue(\"Standard deviation: {sd(overall)}\"))\n","print(glue(\"\"))\n","print(glue(\"This are the most relevant questions and the importance value of each of them:\"))\n","questionsResults = data.frame(questions$names, questions$value)\n","knitr::kable(questionsResults)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bRsPt7TdRwS8"},"source":["The most important questions are **18, 11** because they always appear on the list. \n","There are other questions that sometimes appear and other time they do not but we can consider them important as well. (19,16,17)\n","\n","The questions: \n",">- 18. My spouse and I have similar ideas about how marriage should be \n",">- 11. I think that one day in the future, when I look back, I see that my spouse and I have been in harmony with each other.  \n",">- 19. My spouse and I have similar ideas about how roles should be in marriage \n",">- 16. We're compatible with my spouse about what love should be. \n",">- 17. We share the same views about being happy in our life with my spouse "]},{"cell_type":"markdown","metadata":{"id":"JwiNa7DG8niI"},"source":["### An End-to-End example 👀\n","(but please, in your solution do not do like me and use more than one cell to organize the code, when possible 🙂)"]},{"cell_type":"code","metadata":{"id":"voPdQ3NG8oJN"},"source":["data = read.table(file=\"https://raw.githubusercontent.com/HaizeaR/Sistemas-Inteligentes-Files/main/2020%20covid-19-recommendations.tab\", header = T, stringsAsFactors = T)\n","# Remove unuseful columns\n","knitr::kable(head(data), caption = \"A glipmse of the data\")\n","\n","# Get indexes to do partitions\n","perc = 0.80\n","index.train = createDataPartition(y = data$TARGET, p = perc, list = FALSE)\n","\n","# Getting partitions\n","data.train = data[ index.train, ]\n","data.test  = data[-index.train, ]\n","print(glue(\"\"))\n","print(glue(\"Size of the training set: {nrow(data.train)}\"))\n","print(glue(\"Size of the test set: {nrow(data.test)}\"))\n","\n","# Create Linear Model using training data. Formula = all the columns except Score\n","model = rpart(formula = TARGET ~., data = data.train)\n","print(model)\n","\n","# Make the prediction using the model and test data\n","prediction = predict(model, data.test, type= \"class\")\n","\n","# Display Confusion Matrix\n","print(glue(\"\"))\n","mat = caret::confusionMatrix(data.test$TARGET, prediction)\n","mat$table\n","\n","# Print the accuracy \n","print(glue(\"\"))\n","print(glue(\"The model hits in {round(100*mat$overall[[1]],2)} % of the patients\"))"],"execution_count":null,"outputs":[]}]}